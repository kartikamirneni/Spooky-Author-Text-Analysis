{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,roc_auc_score,log_loss, accuracy_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data \n",
      "         id                                               text author\n",
      "0  id26305  This process, however, afforded me no means of...    EAP\n",
      "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
      "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
      "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
      "4  id12958  Finding nothing else, not even gold, the Super...    HPL \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "print('Train Data \\n',train_data.head(),'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution in Data\n",
      " EAP    7900\n",
      "MWS    6044\n",
      "HPL    5635\n",
      "Name: author, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Class Distribution in Data\\n', train_data['author'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Text/Data Cleaning\n",
    "\n",
    "def clean_text(df):\n",
    "    ps = PorterStemmer()\n",
    "    corpus = []\n",
    "    for i in range(0, len(df)):        \n",
    "        review = re.sub('[^A-Za-z0-9]',\" \",df['text'][i])\n",
    "        review = word_tokenize(review)        \n",
    "        review = [word for word in review if word.lower() not in set(stopwords.words('english')) \\\n",
    "                                                     and not word in string.punctuation \\\n",
    "                                                     and not word in (\"''\",\"'s\",\"``\")]\n",
    "        review = [ps.stem(word) for word in review]\n",
    "        review = ' '.join(review)\n",
    "        corpus.append(review)\n",
    "    \n",
    "    return corpus\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                                               text author  \\\n",
      "0  id26305  This process, however, afforded me no means of...    EAP   \n",
      "1  id17569  It never once occurred to me that the fumbling...    HPL   \n",
      "2  id11008  In his left hand was a gold snuff box, from wh...    EAP   \n",
      "3  id27763  How lovely is spring As we looked from Windsor...    MWS   \n",
      "4  id12958  Finding nothing else, not even gold, the Super...    HPL   \n",
      "\n",
      "                                          clean_text  author_num  \n",
      "0  process howev afford mean ascertain dimens dun...           0  \n",
      "1                never occur fumbl might mere mistak           1  \n",
      "2  left hand gold snuff box caper hill cut manner...           0  \n",
      "3  love spring look windsor terrac sixteen fertil...           2  \n",
      "4  find noth els even gold superintend abandon at...           1  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data['clean_text'] = clean_text(train_data)\n",
    "\n",
    "train_data['author_num'] = train_data.author.map({'EAP':0, 'HPL':1, 'MWS':2})\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data['clean_text'], train_data['author_num'],\\\n",
    "                                                                 test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Data Confusion matrix\n",
      " [[1590  437  326]\n",
      " [ 949  501  231]\n",
      " [1122  366  352]]\n",
      "\n",
      "Accuracy on Test Data %: \n",
      " 41.59005788219272\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "tfidf_vec = TfidfVectorizer(token_pattern=r'\\w{1,}', ngram_range=(1, 10), analyzer = 'word',max_features=5000)\n",
    "\n",
    "x_train_tfidf = tfidf_vec.fit_transform(X_train).toarray()\n",
    "x_test_tfidf = tfidf_vec.fit_transform(X_test).toarray()\n",
    "\n",
    "## Model Fitting\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "log_reg.fit(x_train_tfidf, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = log_reg.predict(x_test_tfidf)\n",
    "\n",
    "# Model Evaluation\n",
    "print(\"\\nTrain Data Confusion matrix\\n\", metrics.confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nAccuracy on Test Data %: \\n\", accuracy_score(y_test, y_pred)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Data Confusion matrix\n",
      " [[1180  693  480]\n",
      " [ 703  675  303]\n",
      " [ 864  518  458]]\n",
      "\n",
      "Accuracy on Test Data %: \n",
      " 39.376915219611845\n"
     ]
    }
   ],
   "source": [
    "## Using Grid Search Cross validation \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [1, 10, 100, 1000]}#, 'kernel': ['rbf']}\n",
    "\n",
    "GS_clf = GridSearchCV(log_reg, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "GS_clf.fit(x_train_tfidf, y_train)\n",
    "\n",
    "## Prediction\n",
    "GS_y_pred = GS_clf.predict(x_test_tfidf)\n",
    "\n",
    "## Model Evaluation\n",
    "print(\"\\nTrain Data Confusion matrix\\n\", metrics.confusion_matrix(y_test, GS_y_pred))\n",
    "print(\"\\nAccuracy on Test Data %: \\n\", accuracy_score(y_test, GS_y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ValueError: 'confusion_matrix' is not a valid scoring value. Valid options are ['accuracy', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'average_precision', 'completeness_score', 'explained_variance', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'fowlkes_mallows_score', 'homogeneity_score', 'mutual_info_score', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_median_absolute_error', 'normalized_mutual_info_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc', 'v_measure_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
